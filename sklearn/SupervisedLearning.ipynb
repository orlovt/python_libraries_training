{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Regression\n",
    "\n",
    "We won't go over every model, in fact I will stick to as few as possible models but go over how they are used and what their commonalities are.\n",
    "\n",
    "We will first start off by importing some toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "\n",
    "X, y = datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next we will do the training. Models have two states:\n",
    "\n",
    "1. Instantiated\n",
    "2. Fit\n",
    "\n",
    "When we instantiate the model we specify the hyperparameters of the model and nothing else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyclic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Linear regression with combined L1 and L2 priors as regularizer.\n",
       "\n",
       "Minimizes the objective function::\n",
       "\n",
       "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
       "        + alpha * l1_ratio * ||w||_1\n",
       "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
       "\n",
       "If you are interested in controlling the L1 and L2 penalty\n",
       "separately, keep in mind that this is equivalent to::\n",
       "\n",
       "        a * L1 + b * L2\n",
       "\n",
       "where::\n",
       "\n",
       "        alpha = a + b and l1_ratio = a / (a + b)\n",
       "\n",
       "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
       "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
       "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
       "unless you supply your own sequence of alpha.\n",
       "\n",
       "Read more in the :ref:`User Guide <elastic_net>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "alpha : float, default=1.0\n",
       "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
       "    See the notes for the exact mathematical meaning of this\n",
       "    parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
       "    solved by the :class:`LinearRegression` object. For numerical\n",
       "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
       "    Given this, you should use the :class:`LinearRegression` object.\n",
       "\n",
       "l1_ratio : float, default=0.5\n",
       "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
       "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
       "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
       "    combination of L1 and L2.\n",
       "\n",
       "fit_intercept : bool, default=True\n",
       "    Whether the intercept should be estimated or not. If ``False``, the\n",
       "    data is assumed to be already centered.\n",
       "\n",
       "normalize : bool, default=False\n",
       "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
       "    If True, the regressors X will be normalized before regression by\n",
       "    subtracting the mean and dividing by the l2-norm.\n",
       "    If you wish to standardize, please use\n",
       "    :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
       "    on an estimator with ``normalize=False``.\n",
       "\n",
       "precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
       "    Whether to use a precomputed Gram matrix to speed up\n",
       "    calculations. The Gram matrix can also be passed as argument.\n",
       "    For sparse input this option is always ``True`` to preserve sparsity.\n",
       "\n",
       "max_iter : int, default=1000\n",
       "    The maximum number of iterations\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If ``True``, X will be copied; else, it may be overwritten.\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    The tolerance for the optimization: if the updates are\n",
       "    smaller than ``tol``, the optimization code checks the\n",
       "    dual gap for optimality and continues until it is smaller\n",
       "    than ``tol``.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to ``True``, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive.\n",
       "\n",
       "random_state : int, RandomState instance, default=None\n",
       "    The seed of the pseudo random number generator that selects a random\n",
       "    feature to update. Used when ``selection`` == 'random'.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "selection : {'cyclic', 'random'}, default='cyclic'\n",
       "    If set to 'random', a random coefficient is updated every iteration\n",
       "    rather than looping over features sequentially by default. This\n",
       "    (setting to 'random') often leads to significantly faster convergence\n",
       "    especially when tol is higher than 1e-4.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
       "    parameter vector (w in the cost function formula)\n",
       "\n",
       "sparse_coef_ : sparse matrix of shape (n_features, 1) or             (n_targets, n_features)\n",
       "    ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
       "\n",
       "intercept_ : float or ndarray of shape (n_targets,)\n",
       "    independent term in decision function.\n",
       "\n",
       "n_iter_ : list of int\n",
       "    number of iterations run by the coordinate descent solver to reach\n",
       "    the specified tolerance.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.linear_model import ElasticNet\n",
       ">>> from sklearn.datasets import make_regression\n",
       "\n",
       ">>> X, y = make_regression(n_features=2, random_state=0)\n",
       ">>> regr = ElasticNet(random_state=0)\n",
       ">>> regr.fit(X, y)\n",
       "ElasticNet(random_state=0)\n",
       ">>> print(regr.coef_)\n",
       "[18.83816048 64.55968825]\n",
       ">>> print(regr.intercept_)\n",
       "1.451...\n",
       ">>> print(regr.predict([[0, 0]]))\n",
       "[1.451...]\n",
       "\n",
       "\n",
       "Notes\n",
       "-----\n",
       "To avoid unnecessary memory duplication the X argument of the fit method\n",
       "should be directly passed as a Fortran-contiguous numpy array.\n",
       "\n",
       "See also\n",
       "--------\n",
       "ElasticNetCV : Elastic net model with best model selection by\n",
       "    cross-validation.\n",
       "SGDRegressor: implements elastic net regression with incremental training.\n",
       "SGDClassifier: implements logistic regression with elastic net penalty\n",
       "    (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Lasso\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "linear_model.ElasticNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = linear_model.ElasticNet(alpha=.1, l1_ratio=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The next step is fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=0.9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09834252,  0.04971836, -0.03880229,  0.9660197 , -0.        ,\n",
       "        3.59953739, -0.00941143, -1.16532753,  0.27777374, -0.01465562,\n",
       "       -0.77562437,  0.01018345, -0.57555667])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.429919460545246"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.76993389])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267832164923811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the coefficient of determination R^2 of the prediction.\n",
       "\n",
       "The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
       "sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
       "sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
       "The best possible score is 1.0 and it can be negative (because the\n",
       "model can be arbitrarily worse). A constant model that always\n",
       "predicts the expected value of y, disregarding the input features,\n",
       "would get a R^2 score of 0.0.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    Test samples. For some estimators this may be a\n",
       "    precomputed kernel matrix or a list of generic objects instead,\n",
       "    shape = (n_samples, n_samples_fitted),\n",
       "    where n_samples_fitted is the number of\n",
       "    samples used in the fitting for the estimator.\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "    True values for X.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "score : float\n",
       "    R^2 of self.predict(X) wrt. y.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The R2 score used when calling ``score`` on a regressor uses\n",
       "``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
       "with default value of :func:`~sklearn.metrics.r2_score`.\n",
       "This influences the ``score`` method of all the multioutput\n",
       "regressors (except for\n",
       ":class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CV models\n",
    "\n",
    "Some of these models come with a CV model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElasticNetCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyclic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Elastic Net model with iterative fitting along a regularization path.\n",
       "\n",
       "See glossary entry for :term:`cross-validation estimator`.\n",
       "\n",
       "Read more in the :ref:`User Guide <elastic_net>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "l1_ratio : float or list of float, default=0.5\n",
       "    float between 0 and 1 passed to ElasticNet (scaling between\n",
       "    l1 and l2 penalties). For ``l1_ratio = 0``\n",
       "    the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.\n",
       "    For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2\n",
       "    This parameter can be a list, in which case the different\n",
       "    values are tested by cross-validation and the one giving the best\n",
       "    prediction score is used. Note that a good choice of list of\n",
       "    values for l1_ratio is often to put more values close to 1\n",
       "    (i.e. Lasso) and less close to 0 (i.e. Ridge), as in ``[.1, .5, .7,\n",
       "    .9, .95, .99, 1]``\n",
       "\n",
       "eps : float, default=1e-3\n",
       "    Length of the path. ``eps=1e-3`` means that\n",
       "    ``alpha_min / alpha_max = 1e-3``.\n",
       "\n",
       "n_alphas : int, default=100\n",
       "    Number of alphas along the regularization path, used for each l1_ratio.\n",
       "\n",
       "alphas : ndarray, default=None\n",
       "    List of alphas where to compute the models.\n",
       "    If None alphas are set automatically\n",
       "\n",
       "fit_intercept : bool, default=True\n",
       "    whether to calculate the intercept for this model. If set\n",
       "    to false, no intercept will be used in calculations\n",
       "    (i.e. data is expected to be centered).\n",
       "\n",
       "normalize : bool, default=False\n",
       "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
       "    If True, the regressors X will be normalized before regression by\n",
       "    subtracting the mean and dividing by the l2-norm.\n",
       "    If you wish to standardize, please use\n",
       "    :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
       "    on an estimator with ``normalize=False``.\n",
       "\n",
       "precompute : 'auto', bool or array-like of shape (n_features, n_features),                 default='auto'\n",
       "    Whether to use a precomputed Gram matrix to speed up\n",
       "    calculations. If set to ``'auto'`` let us decide. The Gram\n",
       "    matrix can also be passed as argument.\n",
       "\n",
       "max_iter : int, default=1000\n",
       "    The maximum number of iterations\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    The tolerance for the optimization: if the updates are\n",
       "    smaller than ``tol``, the optimization code checks the\n",
       "    dual gap for optimality and continues until it is smaller\n",
       "    than ``tol``.\n",
       "\n",
       "cv : int, cross-validation generator or iterable, default=None\n",
       "    Determines the cross-validation splitting strategy.\n",
       "    Possible inputs for cv are:\n",
       "\n",
       "    - None, to use the default 5-fold cross-validation,\n",
       "    - int, to specify the number of folds.\n",
       "    - :term:`CV splitter`,\n",
       "    - An iterable yielding (train, test) splits as arrays of indices.\n",
       "\n",
       "    For int/None inputs, :class:`KFold` is used.\n",
       "\n",
       "    Refer :ref:`User Guide <cross_validation>` for the various\n",
       "    cross-validation strategies that can be used here.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If ``True``, X will be copied; else, it may be overwritten.\n",
       "\n",
       "verbose : bool or int, default=0\n",
       "    Amount of verbosity.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    Number of CPUs to use during the cross validation.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive.\n",
       "\n",
       "random_state : int, RandomState instance, default=None\n",
       "    The seed of the pseudo random number generator that selects a random\n",
       "    feature to update. Used when ``selection`` == 'random'.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "selection : {'cyclic', 'random'}, default='cyclic'\n",
       "    If set to 'random', a random coefficient is updated every iteration\n",
       "    rather than looping over features sequentially by default. This\n",
       "    (setting to 'random') often leads to significantly faster convergence\n",
       "    especially when tol is higher than 1e-4.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "alpha_ : float\n",
       "    The amount of penalization chosen by cross validation\n",
       "\n",
       "l1_ratio_ : float\n",
       "    The compromise between l1 and l2 penalization chosen by\n",
       "    cross validation\n",
       "\n",
       "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
       "    Parameter vector (w in the cost function formula),\n",
       "\n",
       "intercept_ : float or ndarray of shape (n_targets, n_features)\n",
       "    Independent term in the decision function.\n",
       "\n",
       "mse_path_ : ndarray of shape (n_l1_ratio, n_alpha, n_folds)\n",
       "    Mean square error for the test set on each fold, varying l1_ratio and\n",
       "    alpha.\n",
       "\n",
       "alphas_ : ndarray of shape (n_alphas,) or (n_l1_ratio, n_alphas)\n",
       "    The grid of alphas used for fitting, for each l1_ratio.\n",
       "\n",
       "n_iter_ : int\n",
       "    number of iterations run by the coordinate descent solver to reach\n",
       "    the specified tolerance for the optimal alpha.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.linear_model import ElasticNetCV\n",
       ">>> from sklearn.datasets import make_regression\n",
       "\n",
       ">>> X, y = make_regression(n_features=2, random_state=0)\n",
       ">>> regr = ElasticNetCV(cv=5, random_state=0)\n",
       ">>> regr.fit(X, y)\n",
       "ElasticNetCV(cv=5, random_state=0)\n",
       ">>> print(regr.alpha_)\n",
       "0.199...\n",
       ">>> print(regr.intercept_)\n",
       "0.398...\n",
       ">>> print(regr.predict([[0, 0]]))\n",
       "[0.398...]\n",
       "\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For an example, see\n",
       ":ref:`examples/linear_model/plot_lasso_model_selection.py\n",
       "<sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py>`.\n",
       "\n",
       "To avoid unnecessary memory duplication the X argument of the fit method\n",
       "should be directly passed as a Fortran-contiguous numpy array.\n",
       "\n",
       "The parameter l1_ratio corresponds to alpha in the glmnet R package\n",
       "while alpha corresponds to the lambda parameter in glmnet.\n",
       "More specifically, the optimization objective is::\n",
       "\n",
       "    1 / (2 * n_samples) * ||y - Xw||^2_2\n",
       "    + alpha * l1_ratio * ||w||_1\n",
       "    + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
       "\n",
       "If you are interested in controlling the L1 and L2 penalty\n",
       "separately, keep in mind that this is equivalent to::\n",
       "\n",
       "    a * L1 + b * L2\n",
       "\n",
       "for::\n",
       "\n",
       "    alpha = a + b and l1_ratio = a / (a + b).\n",
       "\n",
       "See also\n",
       "--------\n",
       "enet_path\n",
       "ElasticNet\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_model.ElasticNetCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = linear_model.ElasticNetCV(\n",
    "    l1_ratio=[.1, .5, .7, .9, .95, .99, 1], \n",
    "    n_alphas=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], n_alphas=20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.24820428e+03, 5.03889940e+03, 3.50300657e+03, 2.43526493e+03,\n",
       "        1.69297864e+03, 1.17694655e+03, 8.18204764e+02, 5.68810058e+02,\n",
       "        3.95432655e+02, 2.74901933e+02, 1.91109843e+02, 1.32858186e+02,\n",
       "        9.23620541e+01, 6.42094347e+01, 4.46379364e+01, 3.10319718e+01,\n",
       "        2.15732033e+01, 1.49975355e+01, 1.04261786e+01, 7.24820428e+00],\n",
       "       [1.44964086e+03, 1.00777988e+03, 7.00601313e+02, 4.87052986e+02,\n",
       "        3.38595727e+02, 2.35389310e+02, 1.63640953e+02, 1.13762012e+02,\n",
       "        7.90865309e+01, 5.49803866e+01, 3.82219687e+01, 2.65716373e+01,\n",
       "        1.84724108e+01, 1.28418869e+01, 8.92758728e+00, 6.20639437e+00,\n",
       "        4.31464065e+00, 2.99950710e+00, 2.08523573e+00, 1.44964086e+00],\n",
       "       [1.03545775e+03, 7.19842772e+02, 5.00429509e+02, 3.47894990e+02,\n",
       "        2.41854091e+02, 1.68135222e+02, 1.16886395e+02, 8.12585797e+01,\n",
       "        5.64903792e+01, 3.92717047e+01, 2.73014062e+01, 1.89797409e+01,\n",
       "        1.31945792e+01, 9.17277638e+00, 6.37684806e+00, 4.43313883e+00,\n",
       "        3.08188618e+00, 2.14250507e+00, 1.48945409e+00, 1.03545775e+00],\n",
       "       [8.05356032e+02, 5.59877711e+02, 3.89222952e+02, 2.70584992e+02,\n",
       "        1.88108737e+02, 1.30771839e+02, 9.09116405e+01, 6.32011175e+01,\n",
       "        4.39369616e+01, 3.05446592e+01, 2.12344270e+01, 1.47620207e+01,\n",
       "        1.02624505e+01, 7.13438163e+00, 4.95977071e+00, 3.44799687e+00,\n",
       "        2.39702259e+00, 1.66639283e+00, 1.15846429e+00, 8.05356032e-01],\n",
       "       [7.62968872e+02, 5.30410464e+02, 3.68737533e+02, 2.56343677e+02,\n",
       "        1.78208277e+02, 1.23889111e+02, 8.61268173e+01, 5.98747429e+01,\n",
       "        4.16244900e+01, 2.89370456e+01, 2.01168256e+01, 1.39850723e+01,\n",
       "        9.72232148e+00, 6.75888786e+00, 4.69873015e+00, 3.26652335e+00,\n",
       "        2.27086350e+00, 1.57868795e+00, 1.09749249e+00, 7.62968872e-01],\n",
       "       [7.32141847e+02, 5.08979738e+02, 3.53839047e+02, 2.45986357e+02,\n",
       "        1.71007943e+02, 1.18883490e+02, 8.26469459e+01, 5.74555614e+01,\n",
       "        3.99426924e+01, 2.77678720e+01, 1.93040246e+01, 1.34200188e+01,\n",
       "        9.32950041e+00, 6.48580148e+00, 4.50888247e+00, 3.13454261e+00,\n",
       "        2.17911144e+00, 1.51490258e+00, 1.05314936e+00, 7.32141847e-01],\n",
       "       [7.24820428e+02, 5.03889940e+02, 3.50300657e+02, 2.43526493e+02,\n",
       "        1.69297864e+02, 1.17694655e+02, 8.18204764e+01, 5.68810058e+01,\n",
       "        3.95432655e+01, 2.74901933e+01, 1.91109843e+01, 1.32858186e+01,\n",
       "        9.23620541e+00, 6.42094347e+00, 4.46379364e+00, 3.10319718e+00,\n",
       "        2.15732033e+00, 1.49975355e+00, 1.04261786e+00, 7.24820428e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 34.46313316,  94.87999031, 160.3822969 ,  96.85105338,\n",
       "          91.18228117],\n",
       "        [ 36.01725641,  90.87020824, 152.2615469 ,  88.61576106,\n",
       "          91.18228117],\n",
       "        [ 38.56862106,  88.31600559, 139.33746263,  85.52517035,\n",
       "          75.61821262],\n",
       "        [ 41.23655024,  86.69710072, 130.43823286,  85.11520663,\n",
       "          55.12988262],\n",
       "        [ 43.58589628,  85.66581333, 124.32650653,  86.05236042,\n",
       "          43.2795886 ],\n",
       "        [ 45.2193056 ,  84.49171601, 120.16909351,  87.20101215,\n",
       "          36.53104146],\n",
       "        [ 46.47915464,  83.47037543, 117.35676499,  88.10582451,\n",
       "          32.69544214],\n",
       "        [ 47.41711903,  82.80037365, 115.44292525,  88.78642686,\n",
       "          30.47620643],\n",
       "        [ 47.28174303,  82.35767049, 113.87788592,  89.00232134,\n",
       "          28.89573631],\n",
       "        [ 45.45436715,  80.25621958, 110.00848191,  89.35387088,\n",
       "          25.30706969],\n",
       "        [ 42.81244452,  75.02476883, 105.30196523,  87.23744914,\n",
       "          21.01633294],\n",
       "        [ 40.13526732,  69.82622382, 100.95795157,  84.2666688 ,\n",
       "          18.34078799],\n",
       "        [ 37.43120791,  64.68304311,  96.64855299,  80.57715629,\n",
       "          16.50428888],\n",
       "        [ 34.8001641 ,  59.76510606,  92.51131496,  76.28703037,\n",
       "          15.20360634],\n",
       "        [ 32.37906163,  55.19843143,  88.35504892,  71.68649009,\n",
       "          14.42297974],\n",
       "        [ 29.9875794 ,  50.71078313,  84.50401251,  67.11730916,\n",
       "          14.24729427],\n",
       "        [ 27.84766242,  46.42921851,  80.8630899 ,  63.447152  ,\n",
       "          14.32180947],\n",
       "        [ 25.60017996,  42.67406438,  75.76426681,  59.02916046,\n",
       "          14.85379891],\n",
       "        [ 23.54264198,  39.59398145,  70.36971921,  55.16811806,\n",
       "          15.66258569],\n",
       "        [ 21.64646906,  37.11311626,  65.21182361,  51.96324853,\n",
       "          16.57143773]],\n",
       "\n",
       "       [[ 34.54783689,  94.59422777, 160.3822969 ,  96.72295443,\n",
       "          91.18228117],\n",
       "        [ 36.62387547,  90.27547736, 151.22689204,  87.7135201 ,\n",
       "          91.18228117],\n",
       "        [ 39.527851  ,  87.77391925, 137.55387205,  85.19793969,\n",
       "          73.36339096],\n",
       "        [ 42.27455419,  86.28413928, 128.73533504,  85.33013257,\n",
       "          52.04267997],\n",
       "        [ 44.54338598,  85.37143024, 122.96169923,  86.39558222,\n",
       "          40.87796069],\n",
       "        [ 45.9790633 ,  84.34694201, 119.20441816,  87.52692485,\n",
       "          34.93168656],\n",
       "        [ 47.0371727 ,  83.32203319, 116.68384845,  88.37490239,\n",
       "          31.69166724],\n",
       "        [ 47.81977443,  82.67933266, 114.97593636,  88.99435547,\n",
       "          29.85780533],\n",
       "        [ 47.16250169,  82.26689546, 113.47663736,  88.91274409,\n",
       "          28.3965009 ],\n",
       "        [ 42.86801428,  79.47428931, 107.93030128,  89.29694339,\n",
       "          24.09928379],\n",
       "        [ 36.49040053,  66.41141208,  96.77108624,  79.68629629,\n",
       "          18.39388556],\n",
       "        [ 32.15003046,  56.65160376,  88.62348079,  70.81374288,\n",
       "          15.80938172],\n",
       "        [ 29.42726401,  50.10776464,  83.35589216,  65.35636454,\n",
       "          15.0515003 ],\n",
       "        [ 27.34421585,  45.53852876,  79.72267739,  61.83668096,\n",
       "          15.70244797],\n",
       "        [ 26.07903128,  42.31555013,  76.80705006,  58.86517149,\n",
       "          17.08512459],\n",
       "        [ 24.30771621,  39.63839338,  74.06124323,  55.27903152,\n",
       "          17.76400056],\n",
       "        [ 22.26237622,  36.88939343,  70.09353255,  52.17015266,\n",
       "          18.41522215],\n",
       "        [ 19.81785151,  34.865203  ,  64.51642399,  49.59220755,\n",
       "          18.8190995 ],\n",
       "        [ 17.6387549 ,  33.38879966,  58.12134133,  47.83160384,\n",
       "          18.82147376],\n",
       "        [ 16.02435494,  31.95809181,  53.24353805,  47.01382457,\n",
       "          19.03247236]],\n",
       "\n",
       "       [[ 34.55660062,  94.57015874, 160.3822969 ,  96.71160209,\n",
       "          91.18228117],\n",
       "        [ 36.67749606,  90.22836544, 151.14281496,  87.64405913,\n",
       "          91.18228117],\n",
       "        [ 39.60723824,  87.73269582, 137.41490845,  85.18020184,\n",
       "          73.17726196],\n",
       "        [ 42.35673985,  86.2535395 , 128.60637043,  85.35366027,\n",
       "          51.80348844],\n",
       "        [ 44.61585161,  85.34995824, 122.85958106,  86.42886137,\n",
       "          40.6998157 ],\n",
       "        [ 46.03638669,  84.3372764 , 119.13388511,  87.5535787 ,\n",
       "          34.81634997],\n",
       "        [ 47.07839853,  83.31138906, 116.63522562,  88.3955038 ,\n",
       "          31.62047777],\n",
       "        [ 47.8491812 ,  82.67057906, 114.9423931 ,  89.00980767,\n",
       "          29.81425261],\n",
       "        [ 47.13537959,  82.26034228, 113.44463939,  88.88683443,\n",
       "          28.35689618],\n",
       "        [ 41.97576364,  79.39365442, 107.25999851,  89.28108546,\n",
       "          23.61467207],\n",
       "        [ 34.74679939,  63.7169598 ,  93.92977803,  76.6846009 ,\n",
       "          17.97014092],\n",
       "        [ 30.59792006,  53.57801912,  86.22531418,  67.84445324,\n",
       "          15.88099745],\n",
       "        [ 28.33580262,  47.63735678,  81.3223761 ,  62.93350917,\n",
       "          15.59709309],\n",
       "        [ 26.45858842,  43.49733966,  78.17058413,  60.15441297,\n",
       "          16.6754614 ],\n",
       "        [ 25.52630746,  40.92694034,  74.96878179,  57.21326566,\n",
       "          18.23257745],\n",
       "        [ 23.68390276,  38.40631481,  72.75475261,  53.95497693,\n",
       "          18.58630467],\n",
       "        [ 21.4604163 ,  35.77505932,  68.70794871,  51.02792748,\n",
       "          19.0368288 ],\n",
       "        [ 18.8180744 ,  34.0899352 ,  62.72081981,  48.94418387,\n",
       "          19.26260104],\n",
       "        [ 16.66111417,  33.16323898,  56.01308972,  48.23592466,\n",
       "          18.93266728],\n",
       "        [ 15.03965768,  31.37344309,  51.24624183,  49.00130067,\n",
       "          19.22118342]],\n",
       "\n",
       "       [[ 34.56167674,  94.55653699, 160.3822969 ,  96.70513639,\n",
       "          91.18228117],\n",
       "        [ 36.70800041,  90.20189618, 151.09543533,  87.605191  ,\n",
       "          91.18228117],\n",
       "        [ 39.65205674,  87.70964158, 137.33697775,  85.17077266,\n",
       "          73.07218023],\n",
       "        [ 42.40290689,  86.23647479, 128.53427525,  85.36727718,\n",
       "          51.66944893],\n",
       "        [ 44.65642008,  85.33800382, 122.80256107,  86.44798491,\n",
       "          40.60047107],\n",
       "        [ 46.06842042,  84.33195427, 119.09460475,  87.56860375,\n",
       "          34.75222606],\n",
       "        [ 47.10138314,  83.30547319, 116.60818172,  88.40703267,\n",
       "          31.58096672],\n",
       "        [ 47.86555466,  82.66570949, 114.92374783,  89.0184275 ,\n",
       "          29.79009383],\n",
       "        [ 47.11848667,  82.25669752, 113.42655612,  88.86992581,\n",
       "          28.33452848],\n",
       "        [ 41.18684328,  79.34670324, 106.63186839,  89.27099867,\n",
       "          22.85483686],\n",
       "        [ 33.45481592,  61.557287  ,  92.12808938,  74.12676853,\n",
       "          17.80852121],\n",
       "        [ 29.62335463,  51.45090982,  84.5744157 ,  65.77585165,\n",
       "          16.15401278],\n",
       "        [ 27.55645284,  46.11583021,  80.03073671,  61.43955532,\n",
       "          16.19470763],\n",
       "        [ 25.96827941,  42.30326163,  77.2369345 ,  59.08892914,\n",
       "          17.4749609 ],\n",
       "        [ 25.23913598,  40.18647619,  73.86559481,  56.25709281,\n",
       "          19.04625834],\n",
       "        [ 23.24219709,  37.57096221,  71.99505777,  53.15817263,\n",
       "          19.09298604],\n",
       "        [ 20.9159693 ,  35.12775688,  67.78045767,  50.3198997 ,\n",
       "          19.40231291],\n",
       "        [ 18.11821631,  33.77202007,  61.46534357,  49.48600044,\n",
       "          19.5120787 ],\n",
       "        [ 15.87807707,  33.45593141,  54.53897056,  51.32773038,\n",
       "          18.92893476],\n",
       "        [ 14.07726003,  30.62999005,  49.90986596,  54.86963114,\n",
       "          19.96302341]],\n",
       "\n",
       "       [[ 34.56262851,  94.55400785, 160.3822969 ,  96.70393264,\n",
       "          91.18228117],\n",
       "        [ 36.71367656,  90.19699694, 151.0866545 ,  87.59800956,\n",
       "          91.18228117],\n",
       "        [ 39.66036927,  87.7053828 , 137.32256475,  85.16906983,\n",
       "          73.05269019],\n",
       "        [ 42.41145136,  86.23332624, 128.52095941,  85.36982879,\n",
       "          51.64466675],\n",
       "        [ 44.66391752,  85.3357997 , 122.79203478,  86.45155853,\n",
       "          40.58214158],\n",
       "        [ 46.07433608,  84.33097767, 119.08736146,  87.57138868,\n",
       "          34.74041017],\n",
       "        [ 47.10562351,  83.30438324, 116.60319752,  88.40916296,\n",
       "          31.57369146],\n",
       "        [ 47.86857366,  82.66481196, 114.9203124 ,  89.02001811,\n",
       "          29.78564641],\n",
       "        [ 47.11522202,  82.25602579, 113.42319957,  88.86658963,\n",
       "          28.3303779 ],\n",
       "        [ 41.00261349,  79.3378774 , 106.47908463,  89.26902515,\n",
       "          22.6827416 ],\n",
       "        [ 33.18405383,  61.08245275,  91.75749176,  73.6729281 ,\n",
       "          17.79562516],\n",
       "        [ 29.43694238,  51.02004707,  84.23964672,  65.35604493,\n",
       "          16.23580374],\n",
       "        [ 27.40933968,  45.82455382,  79.77893276,  61.15478829,\n",
       "          16.33967107],\n",
       "        [ 25.87969714,  42.08096383,  77.0421842 ,  58.80828723,\n",
       "          17.64920835],\n",
       "        [ 25.18885966,  40.05277969,  73.6558335 ,  56.08175439,\n",
       "          19.21050612],\n",
       "        [ 23.14631822,  37.39281144,  71.85252984,  53.00370706,\n",
       "          19.18880895],\n",
       "        [ 20.78468178,  35.0191399 ,  67.59036224,  50.18066007,\n",
       "          19.470752  ],\n",
       "        [ 17.97548917,  33.73784537,  61.20655622,  50.11394783,\n",
       "          19.56232681],\n",
       "        [ 15.66944646,  33.4856277 ,  54.23367605,  53.13048218,\n",
       "          18.98426089],\n",
       "        [ 13.79774983,  30.36676165,  49.64081895,  57.75629142,\n",
       "          20.42441544]],\n",
       "\n",
       "       [[ 34.56332403,  94.55216456, 160.3822969 ,  96.70305466,\n",
       "          91.18228117],\n",
       "        [ 36.71781589,  90.19342927, 151.08025801,  87.59278251,\n",
       "          91.18228117],\n",
       "        [ 39.66642586,  87.70228318, 137.31207132,  85.16783817,\n",
       "          73.03848946],\n",
       "        [ 42.41767337,  86.23103538, 128.51126828,  85.37169302,\n",
       "          51.62662556],\n",
       "        [ 44.66937498,  85.33419632, 122.78437485,  86.4541676 ,\n",
       "          40.56880536],\n",
       "        [ 46.07864126,  84.33026817, 119.08209215,  87.57341745,\n",
       "          34.7318161 ],\n",
       "        [ 47.10870865,  83.30359051, 116.59957218,  88.41071355,\n",
       "          31.56840098],\n",
       "        [ 47.87076985,  82.66415911, 114.91781375,  89.02117546,\n",
       "          29.78241249],\n",
       "        [ 47.11281688,  82.2555372 , 113.42075334,  88.86411756,\n",
       "          28.32735322],\n",
       "        [ 40.85859301,  79.33142321, 106.357861  ,  89.26756728,\n",
       "          22.5497476 ],\n",
       "        [ 32.98000969,  60.71882698,  91.47559081,  73.32467787,\n",
       "          17.791455  ],\n",
       "        [ 29.30050391,  50.69898635,  83.98959993,  65.04270409,\n",
       "          16.30328029],\n",
       "        [ 27.30189936,  45.56877478,  79.59300134,  60.94618693,\n",
       "          16.45341475],\n",
       "        [ 25.81580511,  41.91916726,  76.83462763,  58.60310932,\n",
       "          17.78197074],\n",
       "        [ 25.15245985,  39.95646312,  73.50199494,  55.954624  ,\n",
       "          19.33367859],\n",
       "        [ 23.07252621,  37.25634214,  71.74837688,  52.88851633,\n",
       "          19.25869238],\n",
       "        [ 20.68494254,  34.94587697,  67.44734983,  50.07806492,\n",
       "          19.52068506],\n",
       "        [ 17.86907731,  33.72046677,  61.0117968 ,  51.03785843,\n",
       "          19.60240311],\n",
       "        [ 15.48645682,  33.51407532,  54.00343659,  55.23296216,\n",
       "          19.09317179],\n",
       "        [ 13.55400436,  30.12103463,  49.4399146 ,  60.89898792,\n",
       "          20.95613525]],\n",
       "\n",
       "       [[ 34.56348962,  94.55172629, 160.3822969 ,  96.70284583,\n",
       "          91.18228117],\n",
       "        [ 36.71880038,  90.19258138, 151.07873755,  87.59154057,\n",
       "          91.18228117],\n",
       "        [ 39.66786568,  87.70154673, 137.30957773,  85.16754649,\n",
       "          73.03511355],\n",
       "        [ 42.41915207,  86.23049119, 128.50896579,  85.37213683,\n",
       "          51.62233858],\n",
       "        [ 44.67067171,  85.33381547, 122.78255507,  86.4547885 ,\n",
       "          40.5656373 ],\n",
       "        [ 46.07966409,  84.33009975, 119.08084051,  87.5738997 ,\n",
       "          34.72977492],\n",
       "        [ 47.10944153,  83.30340223, 116.5987111 ,  88.41108197,\n",
       "          31.56714457],\n",
       "        [ 47.87129151,  82.66400404, 114.9172203 ,  89.0214504 ,\n",
       "          29.78164451],\n",
       "        [ 47.1122418 ,  82.25542115, 113.42017172,  88.86352469,\n",
       "          28.3266341 ],\n",
       "        [ 40.82304018,  79.32988593, 106.32768678,  89.26721821,\n",
       "          22.51712991],\n",
       "        [ 32.93064467,  60.63007276,  91.40703025,  73.2395947 ,\n",
       "          17.79119673],\n",
       "        [ 29.26801389,  50.62161541,  83.92937939,  64.96728111,\n",
       "          16.32037042],\n",
       "        [ 27.27633735,  45.50757651,  79.54849348,  60.89647543,\n",
       "          16.48151675],\n",
       "        [ 25.80070391,  41.88073787,  76.78499379,  58.55425865,\n",
       "          17.81427736],\n",
       "        [ 25.14398998,  39.9336478 ,  73.46530766,  55.92448646,\n",
       "          19.36340211],\n",
       "        [ 23.05444075,  37.22297348,  71.7235795 ,  52.86085197,\n",
       "          19.27530145],\n",
       "        [ 20.6607052 ,  34.92913932,  67.41275259,  50.05345438,\n",
       "          19.53256199],\n",
       "        [ 17.84346735,  33.71739588,  60.96253216,  51.37136243,\n",
       "          19.61269242],\n",
       "        [ 15.4375438 ,  33.52177445,  53.94614394,  55.92138705,\n",
       "          19.13515669],\n",
       "        [ 13.48976023,  30.05369646,  49.39152006,  61.84062596,\n",
       "          21.11897371]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.mse_path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0354577548246566"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.98076851])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6831524128217572"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification\n",
    "\n",
    "Okay this one is quite quick. And is very much so the same as the above. So to cut to the chase, I'll train a Cross Validated Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "d = datasets.load_iris()\n",
    "\n",
    "print(d.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mCs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Logistic Regression CV (aka logit, MaxEnt) classifier.\n",
       "\n",
       "See glossary entry for :term:`cross-validation estimator`.\n",
       "\n",
       "This class implements logistic regression using liblinear, newton-cg, sag\n",
       "of lbfgs optimizer. The newton-cg, sag and lbfgs solvers support only L2\n",
       "regularization with primal formulation. The liblinear solver supports both\n",
       "L1 and L2 regularization, with a dual formulation only for the L2 penalty.\n",
       "Elastic-Net penalty is only supported by the saga solver.\n",
       "\n",
       "For the grid of `Cs` values and `l1_ratios` values, the best hyperparameter\n",
       "is selected by the cross-validator\n",
       ":class:`~sklearn.model_selection.StratifiedKFold`, but it can be changed\n",
       "using the :term:`cv` parameter. The 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
       "solvers can warm-start the coefficients (see :term:`Glossary<warm_start>`).\n",
       "\n",
       "Read more in the :ref:`User Guide <logistic_regression>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "Cs : int or list of floats, default=10\n",
       "    Each of the values in Cs describes the inverse of regularization\n",
       "    strength. If Cs is as an int, then a grid of Cs values are chosen\n",
       "    in a logarithmic scale between 1e-4 and 1e4.\n",
       "    Like in support vector machines, smaller values specify stronger\n",
       "    regularization.\n",
       "\n",
       "fit_intercept : bool, default=True\n",
       "    Specifies if a constant (a.k.a. bias or intercept) should be\n",
       "    added to the decision function.\n",
       "\n",
       "cv : int or cross-validation generator, default=None\n",
       "    The default cross-validation generator used is Stratified K-Folds.\n",
       "    If an integer is provided, then it is the number of folds used.\n",
       "    See the module :mod:`sklearn.model_selection` module for the\n",
       "    list of possible cross-validation objects.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
       "\n",
       "dual : bool, default=False\n",
       "    Dual or primal formulation. Dual formulation is only implemented for\n",
       "    l2 penalty with liblinear solver. Prefer dual=False when\n",
       "    n_samples > n_features.\n",
       "\n",
       "penalty : {'l1', 'l2', 'elasticnet'}, default='l2'\n",
       "    Used to specify the norm used in the penalization. The 'newton-cg',\n",
       "    'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is\n",
       "    only supported by the 'saga' solver.\n",
       "\n",
       "scoring : str or callable, default=None\n",
       "    A string (see model evaluation documentation) or\n",
       "    a scorer callable object / function with signature\n",
       "    ``scorer(estimator, X, y)``. For a list of scoring functions\n",
       "    that can be used, look at :mod:`sklearn.metrics`. The\n",
       "    default scoring option used is 'accuracy'.\n",
       "\n",
       "solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
       "\n",
       "    Algorithm to use in the optimization problem.\n",
       "\n",
       "    - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
       "      'saga' are faster for large ones.\n",
       "    - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
       "      handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
       "      schemes.\n",
       "    - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
       "      'liblinear' and 'saga' handle L1 penalty.\n",
       "    - 'liblinear' might be slower in LogisticRegressionCV because it does\n",
       "      not handle warm-starting.\n",
       "\n",
       "    Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
       "    features with approximately the same scale. You can preprocess the data\n",
       "    with a scaler from sklearn.preprocessing.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       Stochastic Average Gradient descent solver.\n",
       "    .. versionadded:: 0.19\n",
       "       SAGA solver.\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    Tolerance for stopping criteria.\n",
       "\n",
       "max_iter : int, default=100\n",
       "    Maximum number of iterations of the optimization algorithm.\n",
       "\n",
       "class_weight : dict or 'balanced', default=None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If not given, all classes are supposed to have weight one.\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       class_weight == 'balanced'\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    Number of CPU cores used during the cross-validation loop.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "verbose : int, default=0\n",
       "    For the 'liblinear', 'sag' and 'lbfgs' solvers set verbose to any\n",
       "    positive number for verbosity.\n",
       "\n",
       "refit : bool, default=True\n",
       "    If set to True, the scores are averaged across all folds, and the\n",
       "    coefs and the C that corresponds to the best score is taken, and a\n",
       "    final refit is done using these parameters.\n",
       "    Otherwise the coefs, intercepts and C that correspond to the\n",
       "    best scores across folds are averaged.\n",
       "\n",
       "intercept_scaling : float, default=1\n",
       "    Useful only when the solver 'liblinear' is used\n",
       "    and self.fit_intercept is set to True. In this case, x becomes\n",
       "    [x, self.intercept_scaling],\n",
       "    i.e. a \"synthetic\" feature with constant value equal to\n",
       "    intercept_scaling is appended to the instance vector.\n",
       "    The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
       "\n",
       "    Note! the synthetic feature weight is subject to l1/l2 regularization\n",
       "    as all other features.\n",
       "    To lessen the effect of regularization on synthetic feature weight\n",
       "    (and therefore on the intercept) intercept_scaling has to be increased.\n",
       "\n",
       "multi_class : {'auto, 'ovr', 'multinomial'}, default='auto'\n",
       "    If the option chosen is 'ovr', then a binary problem is fit for each\n",
       "    label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
       "    across the entire probability distribution, *even when the data is\n",
       "    binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
       "    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
       "    and otherwise selects 'multinomial'.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "       Stochastic Average Gradient descent solver for 'multinomial' case.\n",
       "    .. versionchanged:: 0.22\n",
       "        Default changed from 'ovr' to 'auto' in 0.22.\n",
       "\n",
       "random_state : int, RandomState instance, default=None\n",
       "    Used when `solver='sag'`, 'saga' or 'liblinear' to shuffle the data.\n",
       "    Note that this only applies to the solver and not the cross-validation\n",
       "    generator. See :term:`Glossary <random_state>` for details.\n",
       "\n",
       "l1_ratios : list of float, default=None\n",
       "    The list of Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``.\n",
       "    Only used if ``penalty='elasticnet'``. A value of 0 is equivalent to\n",
       "    using ``penalty='l2'``, while 1 is equivalent to using\n",
       "    ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a combination\n",
       "    of L1 and L2.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray of shape (n_classes, )\n",
       "    A list of class labels known to the classifier.\n",
       "\n",
       "coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
       "    Coefficient of the features in the decision function.\n",
       "\n",
       "    `coef_` is of shape (1, n_features) when the given problem\n",
       "    is binary.\n",
       "\n",
       "intercept_ : ndarray of shape (1,) or (n_classes,)\n",
       "    Intercept (a.k.a. bias) added to the decision function.\n",
       "\n",
       "    If `fit_intercept` is set to False, the intercept is set to zero.\n",
       "    `intercept_` is of shape(1,) when the problem is binary.\n",
       "\n",
       "Cs_ : ndarray of shape (n_cs)\n",
       "    Array of C i.e. inverse of regularization parameter values used\n",
       "    for cross-validation.\n",
       "\n",
       "l1_ratios_ : ndarray of shape (n_l1_ratios)\n",
       "    Array of l1_ratios used for cross-validation. If no l1_ratio is used\n",
       "    (i.e. penalty is not 'elasticnet'), this is set to ``[None]``\n",
       "\n",
       "coefs_paths_ : ndarray of shape (n_folds, n_cs, n_features) or                    (n_folds, n_cs, n_features + 1)\n",
       "    dict with classes as the keys, and the path of coefficients obtained\n",
       "    during cross-validating across each fold and then across each Cs\n",
       "    after doing an OvR for the corresponding class as values.\n",
       "    If the 'multi_class' option is set to 'multinomial', then\n",
       "    the coefs_paths are the coefficients corresponding to each class.\n",
       "    Each dict value has shape ``(n_folds, n_cs, n_features)`` or\n",
       "    ``(n_folds, n_cs, n_features + 1)`` depending on whether the\n",
       "    intercept is fit or not. If ``penalty='elasticnet'``, the shape is\n",
       "    ``(n_folds, n_cs, n_l1_ratios_, n_features)`` or\n",
       "    ``(n_folds, n_cs, n_l1_ratios_, n_features + 1)``.\n",
       "\n",
       "scores_ : dict\n",
       "    dict with classes as the keys, and the values as the\n",
       "    grid of scores obtained during cross-validating each fold, after doing\n",
       "    an OvR for the corresponding class. If the 'multi_class' option\n",
       "    given is 'multinomial' then the same scores are repeated across\n",
       "    all classes, since this is the multinomial class. Each dict value\n",
       "    has shape ``(n_folds, n_cs`` or ``(n_folds, n_cs, n_l1_ratios)`` if\n",
       "    ``penalty='elasticnet'``.\n",
       "\n",
       "C_ : ndarray of shape (n_classes,) or (n_classes - 1,)\n",
       "    Array of C that maps to the best scores across every class. If refit is\n",
       "    set to False, then for each class, the best C is the average of the\n",
       "    C's that correspond to the best scores for each fold.\n",
       "    `C_` is of shape(n_classes,) when the problem is binary.\n",
       "\n",
       "l1_ratio_ : ndarray of shape (n_classes,) or (n_classes - 1,)\n",
       "    Array of l1_ratio that maps to the best scores across every class. If\n",
       "    refit is set to False, then for each class, the best l1_ratio is the\n",
       "    average of the l1_ratio's that correspond to the best scores for each\n",
       "    fold.  `l1_ratio_` is of shape(n_classes,) when the problem is binary.\n",
       "\n",
       "n_iter_ : ndarray of shape (n_classes, n_folds, n_cs) or (1, n_folds, n_cs)\n",
       "    Actual number of iterations for all classes, folds and Cs.\n",
       "    In the binary or multinomial cases, the first dimension is equal to 1.\n",
       "    If ``penalty='elasticnet'``, the shape is ``(n_classes, n_folds,\n",
       "    n_cs, n_l1_ratios)`` or ``(1, n_folds, n_cs, n_l1_ratios)``.\n",
       "\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> from sklearn.linear_model import LogisticRegressionCV\n",
       ">>> X, y = load_iris(return_X_y=True)\n",
       ">>> clf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)\n",
       ">>> clf.predict(X[:2, :])\n",
       "array([0, 0])\n",
       ">>> clf.predict_proba(X[:2, :]).shape\n",
       "(2, 3)\n",
       ">>> clf.score(X, y)\n",
       "0.98...\n",
       "\n",
       "See also\n",
       "--------\n",
       "LogisticRegression\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_model.LogisticRegressionCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = linear_model.LogisticRegressionCV(Cs=10, n_jobs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(n_jobs=20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35346644,  2.46957158, -4.9489028 , -2.4931657 ],\n",
       "       [ 1.16087133,  0.09707947, -0.50859771, -2.91951647],\n",
       "       [-0.8074049 , -2.56665105,  5.45750051,  5.41268218]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98599548e-01, 1.40045247e-03, 9.40943979e-18]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_proba([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.40143402e-03, -6.57095990e+00, -3.92048183e+01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_log_proba([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Returns the score using the `scoring` option on the given\n",
       "test data and labels.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    Test samples.\n",
       "\n",
       "y : array-like of shape (n_samples,)\n",
       "    True labels for X.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "score : float\n",
       "    Score of self.predict(X) wrt. y.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
